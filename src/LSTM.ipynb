{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "n-k5rTaA3YKv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import json\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "LxcZcOPR3kf7"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"strandenergylist.json\")\n",
        "data = json.load(f)\n",
        "energy = []\n",
        "strands = []\n",
        "for pair in data:\n",
        "    energy.append(pair[1])\n",
        "    strands.append(pair[0])"
      ],
      "metadata": {
        "id": "EEi9HUWC3fpQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intstrands = []\n",
        "for strand in strands:\n",
        "    intstrand = []\n",
        "    for base in strand:\n",
        "        if base == \"A\":\n",
        "            intstrand.append(0)\n",
        "        if base == \"T\":\n",
        "            intstrand.append(1)\n",
        "        if base == \"C\":\n",
        "            intstrand.append(2)\n",
        "        if base == \"G\":\n",
        "            intstrand.append(3)\n",
        "    intstrands.append(intstrand)"
      ],
      "metadata": {
        "id": "bJsqqrD53iRU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strandstensor = torch.tensor(intstrands)\n",
        "onehotstrands = F.one_hot(strandstensor, num_classes=4)\n",
        "onehotstrands = onehotstrands.reshape(1000000,120)\n",
        "energytensor = torch.tensor(energy)"
      ],
      "metadata": {
        "id": "CtxWXRUQ3iv-"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(onehotstrands.type(torch.float32), energytensor)\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [900000, 100000])\n",
        "dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "testdataloader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "aCvvaJXo3r0D"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RegressionLSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RegressionLSTM, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=120, hidden_size=270, num_layers=2, dropout=0.6)\n",
        "        self.fc1 = nn.Linear(270,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "HcuN91yg32XE"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = RegressionLSTM() \n",
        "lstm.to(device)\n",
        "lstmcriterion = nn.MSELoss()\n",
        "lstmoptimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "RNnq0Ys_4AX2"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_parameters = filter(lambda p: p.requires_grad, lstm.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIpHrycy4N3_",
        "outputId": "6cc7259d-0d01-44ba-9182-fcafb783474b"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1008991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (batch_data, batch_labels) in enumerate(dataloader):\n",
        "        batch_data = batch_data.to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "        \n",
        "        # Zero the parameter gradients\n",
        "        lstmoptimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = lstm(batch_data)\n",
        "\n",
        "        # Compute the loss\n",
        "        \n",
        "        loss = lstmcriterion(outputs, batch_labels.unsqueeze(1))\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the parameters\n",
        "        lstmoptimizer.step()\n",
        "\n",
        "        # Print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 9000 == 8999:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 9000))\n",
        "            running_loss = 0.0\n",
        "    \n",
        "    \n",
        "\n",
        "    totalloss = 0 \n",
        "    with torch.inference_mode():\n",
        "      lstm.eval()\n",
        "      for data, labels in testdataloader:\n",
        "        data = data.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = lstm(data)\n",
        "        loss = lstmcriterion(outputs, labels.unsqueeze(1))\n",
        "        totalloss += loss.item()\n",
        "    \n",
        "    lstm.train()\n",
        "\n",
        "    avgloss = totalloss*batch_size/100000\n",
        "    print('[%d] Test loss: %.3f' %(epoch + 1, avgloss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrYEmtYI4JAj",
        "outputId": "6ee73acd-02fa-4c42-f9f6-5a5d70913c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  9000] loss: 1.169\n",
            "[1, 18000] loss: 1.064\n",
            "[1, 27000] loss: 1.046\n",
            "[1] Test loss: 1.043\n",
            "[2,  9000] loss: 1.032\n",
            "[2, 18000] loss: 1.025\n",
            "[2, 27000] loss: 1.028\n",
            "[2] Test loss: 1.030\n",
            "[3,  9000] loss: 1.017\n",
            "[3, 18000] loss: 1.014\n",
            "[3, 27000] loss: 1.011\n",
            "[3] Test loss: 1.033\n",
            "[4,  9000] loss: 1.002\n",
            "[4, 18000] loss: 1.010\n",
            "[4, 27000] loss: 1.004\n",
            "[4] Test loss: 1.022\n",
            "[5,  9000] loss: 0.995\n",
            "[5, 18000] loss: 0.996\n",
            "[5, 27000] loss: 1.003\n",
            "[5] Test loss: 1.018\n",
            "[6,  9000] loss: 0.988\n",
            "[6, 18000] loss: 0.992\n",
            "[6, 27000] loss: 0.996\n",
            "[6] Test loss: 1.021\n",
            "[7,  9000] loss: 0.981\n",
            "[7, 18000] loss: 0.989\n",
            "[7, 27000] loss: 0.991\n",
            "[7] Test loss: 1.011\n",
            "[8,  9000] loss: 0.978\n",
            "[8, 18000] loss: 0.983\n",
            "[8, 27000] loss: 0.980\n",
            "[8] Test loss: 1.012\n",
            "[9,  9000] loss: 0.980\n",
            "[9, 18000] loss: 0.969\n",
            "[9, 27000] loss: 0.979\n",
            "[9] Test loss: 1.013\n",
            "[10,  9000] loss: 0.972\n",
            "[10, 18000] loss: 0.969\n",
            "[10, 27000] loss: 0.982\n",
            "[10] Test loss: 1.009\n",
            "[11,  9000] loss: 0.966\n",
            "[11, 18000] loss: 0.969\n",
            "[11, 27000] loss: 0.974\n",
            "[11] Test loss: 1.008\n",
            "[12,  9000] loss: 0.960\n",
            "[12, 18000] loss: 0.968\n",
            "[12, 27000] loss: 0.967\n",
            "[12] Test loss: 1.002\n",
            "[13,  9000] loss: 0.959\n",
            "[13, 18000] loss: 0.964\n",
            "[13, 27000] loss: 0.965\n",
            "[13] Test loss: 1.009\n",
            "[14,  9000] loss: 0.956\n",
            "[14, 18000] loss: 0.962\n",
            "[14, 27000] loss: 0.960\n",
            "[14] Test loss: 1.001\n",
            "[15,  9000] loss: 0.957\n",
            "[15, 18000] loss: 0.960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(lstm.state_dict(),\"lstm1M2.pt\")"
      ],
      "metadata": {
        "id": "hQKwVSX95XS1"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testoutputs = []\n",
        "testlabels = []\n",
        "\n",
        "totalloss = 0 \n",
        "with torch.inference_mode():\n",
        "  for data, labels in testdataloader:\n",
        "    data = data.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = lstm(data)\n",
        "    loss = lstmcriterion(outputs, labels.unsqueeze(1))\n",
        "    totalloss += loss.item()\n",
        "    testoutputs.append(outputs)\n",
        "    testlabels.append(labels)\n",
        "\n",
        "avgloss = totalloss*batch_size/100000"
      ],
      "metadata": {
        "id": "sEketg3i4bpA"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(avgloss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC0ZBnAS7qkv",
        "outputId": "d1b74d63-e6fd-4dcf-e585-f6b023492a2b"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0431535211086274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in zip(testoutputs, testlabels):\n",
        "  print(i, end=\"\")\n",
        "  print(j)"
      ],
      "metadata": {
        "id": "TOPdiTwA4cXU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}