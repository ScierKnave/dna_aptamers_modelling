{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qahMf4IuMFZS"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.set_default_tensor_type('torch.cuda.FloatTensor')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer HyperHPeters\n",
        "# The length of our token sequences\n",
        "ntokens_HP = 30\n",
        "# Number of attention heads\n",
        "nheads_HP = 16\n",
        "# The encoding dimensions of our tokens\n",
        "token_encode_size_HP = 16\n",
        "# The embedding string size\n",
        "# Pytorch will cut this embedded sequence \n",
        "# and give an equal amount to each head, different \n",
        "# than in theory \n",
        "embed_size_HP = token_encode_size_HP *  nheads_HP\n",
        "# Output size of the heads, which \n",
        "# learn an embedding.\n",
        "head_embedsize_HP = 4\n",
        "# No dropout for now\n",
        "dropout_HP = 0.1\n",
        "# Number of encoding layers\n",
        "n_encoders_HP = 6\n",
        "\n",
        "# Standard stuff\n",
        "activation_HP = \"relu\"\n",
        "layer_norm_eps_HP = 1e-5\n",
        "batch_first_HP = True\n",
        "norm_first_HP = False\n",
        "\n",
        "# Trainig and validation Hyperparameters\n",
        "datasetsize_HP = 1000000\n",
        "split_HP = 0.9\n",
        "batchsize_HP = 256\n",
        "batchsize_HP = min(batchsize_HP, (int)(datasetsize_HP*0.2))\n",
        "nepochs_HP = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loss_HP = nn.MSELoss()\n",
        "learnrate_HP = 1e-4"
      ],
      "metadata": {
        "id": "W9526JrnML6H"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Json -> Dataframe\n",
        "features_df = pd.read_json('strandenergylist.json')\n",
        "energy_df = features_df[1]\n",
        "energy_df = energy_df.head(datasetsize_HP)\n",
        "features_df = features_df.head(datasetsize_HP)\n",
        "features_df = features_df[0].str.split('', expand=True)\n",
        "features_df = features_df.drop([0, 31], axis=1)\n",
        "labels_df = features_df[1]\n",
        "\n",
        "\n",
        "# Dataframe -> Tensors\n",
        "dna = features_df.to_numpy()\n",
        "for i in range(dna.shape[0]):\n",
        "    for j in range(dna.shape[1]):\n",
        "        if (dna[i,j] == 'A'): dna[i,j] = 0\n",
        "        if (dna[i,j] == 'C'): dna[i,j] = 1\n",
        "        if (dna[i,j] == 'G'): dna[i,j] = 2\n",
        "        if (dna[i,j] == 'T'): dna[i,j] = 3\n",
        "dna = dna.astype(int)\n",
        "dna = torch.from_numpy(dna)\n",
        "energy = torch.tensor(energy_df.values).to(torch.float)\n",
        "\n",
        "\n",
        "# Tensors -> Dataloaders\n",
        "dataset = TensorDataset(dna, energy)\n",
        "ntrain = (int) (split_HP * datasetsize_HP)\n",
        "ntest = datasetsize_HP - ntrain\n",
        "train_set, vali_set = torch.utils.data.random_split(dataset, [ntrain, ntest], \n",
        "                                                    generator=torch.Generator(device='cuda'))\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=batchsize_HP, shuffle=True, \n",
        "                              generator=torch.Generator(device='cuda'))\n",
        "vali_dataloader = DataLoader(vali_set, batch_size=1, shuffle=False, \n",
        "                             generator=torch.Generator(device='cuda'))"
      ],
      "metadata": {
        "id": "-suBGKm8MP_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Created entirely by the Pytorch team and pasted here.\n",
        "# Adds information of position in the encoding of the tokens.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class RegressionTranformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RegressionTranformer, self).__init__()\n",
        "\n",
        "        # Takes indexed sequences of tokens and embeds them.\n",
        "        # [batch_size, seq_len] -> [seq_len, batch_size, embedding_dim] TODO check this!\n",
        "        self.embedder = nn.Embedding(ntokens_HP, embed_size_HP)\n",
        "\n",
        "        # Will add information about position in sequence to each token.\n",
        "        # The second argument is the dropout probability.\n",
        "        # [seq_len, batch_size, embedding_dim] -> [seq_len, batch_size, embedding_dim] TODO check this!\n",
        "        self.posi_encoder = PositionalEncoding(embed_size_HP, 0.5)\n",
        "\n",
        "        # The core of our regression transformer\n",
        "        transformer_encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model = embed_size_HP,\n",
        "            nhead = nheads_HP,\n",
        "            dropout = dropout_HP,\n",
        "            activation = activation_HP,\n",
        "            layer_norm_eps = layer_norm_eps_HP,\n",
        "            batch_first = batch_first_HP,\n",
        "            norm_first = norm_first_HP\n",
        "        )\n",
        "        self.encoding_layers = nn.TransformerEncoder(transformer_encoder_layer, n_encoders_HP)\n",
        "\n",
        "      \n",
        "        # A linear map returning a scalar value, which is the predicted free\n",
        "        # energy of the input sequence.\n",
        "        # [batch_size, flatten_seq_len] -> [1]\n",
        "        self.linear = nn.Linear(embed_size_HP * ntokens_HP, 1) \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        ŷ =  self.embedder(x)\n",
        "\n",
        "        # Normalise the encoding.\n",
        "        ŷ = ŷ * (1 / math.sqrt(embed_size_HP))\n",
        "\n",
        "        # Add positionnal encoding\n",
        "        ŷ = torch.permute(ŷ, (1,0,2)) # Necessary for the posi. enc. function.\n",
        "        ŷ = self.posi_encoder(ŷ)\n",
        "\n",
        "        # Apply the attention mechanisms\n",
        "        ŷ = torch.permute(ŷ, (1,0,2)) # Back to normal\n",
        "        ŷ = self.encoding_layers(ŷ)\n",
        "\n",
        "        # Flatten the outputs\n",
        "        ŷ = ŷ.flatten(1,2)\n",
        "\n",
        "        # Apply last linear layer for regression\n",
        "        ŷ = self.linear(ŷ)\n",
        "\n",
        "        return ŷ\n",
        "        \n",
        "transformer = RegressionTranformer().to(device)"
      ],
      "metadata": {
        "id": "3IKiCGjxMSR8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_parameters = filter(lambda p: p.requires_grad, transformer.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(params)"
      ],
      "metadata": {
        "id": "BUL74wx9MSzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d024a4e3-7699-46d8-bc6b-c76e5b307929"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7905793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.load_state_dict(torch.load(\"transformer_weights.pt\"))"
      ],
      "metadata": {
        "id": "978THcTfMVbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = np.empty((100000, 2))\n",
        "with torch.inference_mode():\n",
        "      total = 0\n",
        "      transformer.eval()\n",
        "      for i, (x_batch, y_batch) in enumerate(vali_dataloader):\n",
        "            x_batch = x_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            ŷ_batch = transformer(x_batch)\n",
        "            predictions[i] = np.array([y_batch.squeeze(0).cpu().numpy(),ŷ_batch.squeeze(0).cpu().numpy()])\n",
        "            batch_loss = loss_HP(ŷ_batch, y_batch.unsqueeze(1))\n",
        "            total += batchsize_HP * batch_loss.item()\n",
        "\n",
        "print(total / (datasetsize_HP*(1-split_HP)))"
      ],
      "metadata": {
        "id": "UtS8rxG0MWsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(predictions, columns=[\"true\", \"predict\"])\n",
        "df = df.sort_values('true', ascending=True)\n",
        "df.to_csv('data.csv', index=False)"
      ],
      "metadata": {
        "id": "kQ24XdkeMYf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Start here if data.csv is already available\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "QP37-N30Nzhi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data.csv')"
      ],
      "metadata": {
        "id": "DTBmbq2pNGBi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"true\"].mean())\n",
        "print(df[\"predict\"].mean())\n",
        "print(df[\"true\"].var())\n",
        "print(df[\"predict\"].var())\n",
        "bias = df[\"predict\"].mean() - df[\"true\"].mean()\n",
        "print(\"Bias:\", bias)\n",
        "mse = mean_squared_error(df['true'], df['predict']) \n",
        "print(\"MSE:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvhAVs-AMdDx",
        "outputId": "2dc71d91-7bfb-4d50-b8f7-e8924c9251de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-3.3444169298785926\n",
            "-3.613931269560456\n",
            "1.6480939434500332\n",
            "2.050099039899456\n",
            "Bias: -0.26951433968186356\n",
            "MSE: 0.15640475240276502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nrows = len(df)\n",
        "\n",
        "# calculate the row indices for the four dataframes\n",
        "indices = [0, int(nrows/4), int(nrows/2), int(3*nrows/4), nrows]\n",
        "\n",
        "# split the dataframe into four parts\n",
        "df1 = df.iloc[indices[0]:indices[1], :]\n",
        "df2 = df.iloc[indices[1]:indices[2], :]\n",
        "df3 = df.iloc[indices[2]:indices[3], :]\n",
        "df4 = df.iloc[indices[3]:indices[4], :]"
      ],
      "metadata": {
        "id": "-GT11sM-Mesg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1[\"true\"].mean())\n",
        "print(df1[\"predict\"].mean())\n",
        "print(df1[\"true\"].var())\n",
        "print(df1[\"predict\"].var())\n",
        "bias1 = df1[\"predict\"].mean() - df1[\"true\"].mean()\n",
        "print(\"Bias:\", bias1)\n",
        "mse1 = mean_squared_error(df1['true'], df1['predict']) \n",
        "print(\"MSE:\", mse1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1qoUQ6CMgEx",
        "outputId": "e493e5ad-ddaa-4f66-ab27-6475a9618be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-5.1042546160125735\n",
            "-5.546279947891235\n",
            "1.0123730389034757\n",
            "1.3016918702774098\n",
            "Bias: -0.44202533187866155\n",
            "MSE: 0.3500080830016833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df2[\"true\"].mean())\n",
        "print(df2[\"predict\"].mean())\n",
        "print(df2[\"true\"].var())\n",
        "print(df2[\"predict\"].var())\n",
        "bias2 = df2[\"predict\"].mean() - df2[\"true\"].mean()\n",
        "print(\"Bias:\", bias2)\n",
        "mse2 = mean_squared_error(df2['true'], df2['predict']) \n",
        "print(\"MSE:\", mse2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hTEFRJ7NhSQ",
        "outputId": "af119568-7658-4e33-fecb-ad0ee9c32c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-3.5342422819328307\n",
            "-3.8354614467525483\n",
            "0.06712383722660288\n",
            "0.14644732888146372\n",
            "Bias: -0.30121916481971756\n",
            "MSE: 0.15641848534270264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df3[\"true\"].mean())\n",
        "print(df3[\"predict\"].mean())\n",
        "print(df3[\"true\"].var())\n",
        "print(df3[\"predict\"].var())\n",
        "bias3 = df3[\"predict\"].mean() - df3[\"true\"].mean()\n",
        "print(\"Bias:\", bias3)\n",
        "mse3 = mean_squared_error(df3['true'], df3['predict']) \n",
        "print(\"MSE:\", mse3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKtNQAnONij7",
        "outputId": "fdca27c8-3815-4c6d-c75b-dc6944f56528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-2.7710489375782013\n",
            "-2.9849057734155653\n",
            "0.03935028202795005\n",
            "0.08768561501785845\n",
            "Bias: -0.21385683583736403\n",
            "MSE: 0.08447276574759723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df4[\"true\"].mean())\n",
        "print(df4[\"predict\"].mean())\n",
        "print(df4[\"true\"].var())\n",
        "print(df4[\"predict\"].var())\n",
        "bias4 = df4[\"predict\"].mean() - df4[\"true\"].mean()\n",
        "print(\"Bias:\", bias4)\n",
        "mse4 = mean_squared_error(df4['true'], df4['predict']) \n",
        "print(\"MSE:\", mse4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfR7ClGCNjfo",
        "outputId": "4d110828-bd47-4356-c5f7-fe06089d9e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.9681218839907646\n",
            "-2.089077910182476\n",
            "0.11751089245651318\n",
            "0.16065932436493185\n",
            "Bias: -0.12095602619171153\n",
            "MSE: 0.03471967551907703\n"
          ]
        }
      ]
    }
  ]
}